{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "type(pd.read_csv('ds_salaries.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Spark Session\n",
    "Lesson: getOrCreate not getorCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-M7L9CQF7.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b56a5d0bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('ds_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|      _c0|             _c1|            _c2|                 _c3|   _c4|            _c5|          _c6|               _c7|         _c8|             _c9|        _c10|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LESSON\n",
    "df_pyspark = spark.read.option('header','true').csv('ds_salaries.csv').show gives the output of type as none. To get the type or print schema you have to remove .show\n",
    "\n",
    "inferSchema = makes sure column data types are valid. Without inferSchema all columns are of data type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('ds_salaries.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is data structure where we can perform several operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('ds_salaries.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Columns and Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work_year',\n",
       " 'experience_level',\n",
       " 'employment_type',\n",
       " 'job_title',\n",
       " 'salary',\n",
       " 'salary_currency',\n",
       " 'salary_in_usd',\n",
       " 'employee_residence',\n",
       " 'remote_ratio',\n",
       " 'company_location',\n",
       " 'company_size']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(work_year=2023, experience_level='SE', employment_type='FT', job_title='Principal Data Scientist', salary=80000, salary_currency='EUR', salary_in_usd=85847, employee_residence='ES', remote_ratio=100, company_location='ES', company_size='L')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick One Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.select('work_year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick Multipe Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[work_year: int, experience_level: string]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(['work_year', 'experience_level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work_year', 'int'),\n",
       " ('experience_level', 'string'),\n",
       " ('employment_type', 'string'),\n",
       " ('job_title', 'string'),\n",
       " ('salary', 'int'),\n",
       " ('salary_currency', 'string'),\n",
       " ('salary_in_usd', 'int'),\n",
       " ('employee_residence', 'string'),\n",
       " ('remote_ratio', 'int'),\n",
       " ('company_location', 'string'),\n",
       " ('company_size', 'string')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+---------------+--------------------+------------------+---------------+------------------+------------------+------------------+----------------+------------+\n",
      "|summary|         work_year|experience_level|employment_type|           job_title|            salary|salary_currency|     salary_in_usd|employee_residence|      remote_ratio|company_location|company_size|\n",
      "+-------+------------------+----------------+---------------+--------------------+------------------+---------------+------------------+------------------+------------------+----------------+------------+\n",
      "|  count|              3755|            3755|           3755|                3755|              3755|           3755|              3755|              3755|              3755|            3755|        3755|\n",
      "|   mean|2022.3736351531293|            NULL|           NULL|                NULL|190695.57177097205|           NULL|137570.38988015978|              NULL|46.271637816245004|            NULL|        NULL|\n",
      "| stddev|0.6914482342677833|            NULL|           NULL|                NULL| 671676.5005079063|           NULL|63055.625278224135|              NULL|48.589050470587495|            NULL|        NULL|\n",
      "|    min|              2020|              EN|             CT|3D Computer Visio...|              6000|            AUD|              5132|                AE|                 0|              AE|           L|\n",
      "|    max|              2023|              SE|             PT|Staff Data Scientist|          30400000|            USD|            450000|                VN|               100|              VN|           S|\n",
      "+-------+------------------+----------------+---------------+--------------------+------------------+---------------+------------------+------------------+------------------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Columns in Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+-------------+\n",
      "|work_year|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|yearly salary|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+-------------+\n",
      "|     2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|       960000|\n",
      "|     2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|       360000|\n",
      "|     2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|       306000|\n",
      "|     2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|      2100000|\n",
      "|     2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|      1440000|\n",
      "|     2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|      2666400|\n",
      "|     2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|      1632000|\n",
      "|     2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|      2628000|\n",
      "|     2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|      1692000|\n",
      "|     2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|      1765200|\n",
      "|     2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|      1088400|\n",
      "|     2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|      1560000|\n",
      "|     2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|      1200000|\n",
      "|     2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|      2563920|\n",
      "|     2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|      1569120|\n",
      "|     2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|      1765200|\n",
      "|     2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|      1088400|\n",
      "|     2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|      2040000|\n",
      "|     2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|      1800000|\n",
      "|     2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|      1800000|\n",
      "+---------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yearly_salary = df_pyspark.withColumn('yearly salary', df_pyspark['salary']*12).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ysalary = df_pyspark.drop('yearly_salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_salary = spark.read.csv('ds_salaries.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|year_employed|experience_level|employment_type|           job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+-------------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|         2023|              SE|             FT|Principal Data Sc...| 80000|            EUR|        85847|                ES|         100|              ES|           L|\n",
      "|         2023|              MI|             CT|         ML Engineer| 30000|            USD|        30000|                US|         100|              US|           S|\n",
      "|         2023|              MI|             CT|         ML Engineer| 25500|            USD|        25500|                US|         100|              US|           S|\n",
      "|         2023|              SE|             FT|      Data Scientist|175000|            USD|       175000|                CA|         100|              CA|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist|120000|            USD|       120000|                CA|         100|              CA|           M|\n",
      "|         2023|              SE|             FT|   Applied Scientist|222200|            USD|       222200|                US|           0|              US|           L|\n",
      "|         2023|              SE|             FT|   Applied Scientist|136000|            USD|       136000|                US|           0|              US|           L|\n",
      "|         2023|              SE|             FT|      Data Scientist|219000|            USD|       219000|                CA|           0|              CA|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist|141000|            USD|       141000|                CA|           0|              CA|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|         2023|              SE|             FT|        Data Analyst|130000|            USD|       130000|                US|         100|              US|           M|\n",
      "|         2023|              SE|             FT|        Data Analyst|100000|            USD|       100000|                US|         100|              US|           M|\n",
      "|         2023|              EN|             FT|   Applied Scientist|213660|            USD|       213660|                US|           0|              US|           L|\n",
      "|         2023|              EN|             FT|   Applied Scientist|130760|            USD|       130760|                US|           0|              US|           L|\n",
      "|         2023|              SE|             FT|        Data Modeler|147100|            USD|       147100|                US|           0|              US|           M|\n",
      "|         2023|              SE|             FT|        Data Modeler| 90700|            USD|        90700|                US|           0|              US|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist|170000|            USD|       170000|                US|           0|              US|           M|\n",
      "|         2023|              SE|             FT|      Data Scientist|150000|            USD|       150000|                US|           0|              US|           M|\n",
      "|         2023|              MI|             FT|        Data Analyst|150000|            USD|       150000|                US|         100|              US|           M|\n",
      "+-------------+----------------+---------------+--------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('work_year', 'year_employed').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
